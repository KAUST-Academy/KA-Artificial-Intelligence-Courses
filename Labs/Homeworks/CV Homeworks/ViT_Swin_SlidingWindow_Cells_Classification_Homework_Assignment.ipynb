{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ded4c373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T18:31:27.388408Z",
     "iopub.status.busy": "2025-07-31T18:31:27.388056Z",
     "iopub.status.idle": "2025-07-31T18:31:27.399191Z",
     "shell.execute_reply": "2025-07-31T18:31:27.397933Z",
     "shell.execute_reply.started": "2025-07-31T18:31:27.388381Z"
    },
    "papermill": {
     "duration": 0.003048,
     "end_time": "2025-07-31T19:37:34.469752",
     "exception": false,
     "start_time": "2025-07-31T19:37:34.466704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Banner](https://i.imgur.com/a3uAqnb.png)\n",
    "\n",
    "# Cell Classification using ViT + Swin Transformers (Sliding-Window Approach)\n",
    "\n",
    "In this homework, we will classify biomedical cell images using two Vision Transformer architectures:\n",
    "- **ViT-B/16**\n",
    "- **Swin-T**\n",
    "\n",
    "The images have sizes 700*500. Both backbones require inputs of size **224√ó224**, which is smaller than the actual image sizes. Instead of resizing (which may distort the cell structure), we adopt a **sliding-window** approach:\n",
    "- **Training**: we randomly crop 224√ó224 windows\n",
    "- **Validation**: we center crop 224√ó224\n",
    "- **Inference**: we slide a window over the full image and average the probabilities across windows to classify the full image.\n",
    "\n",
    "Sliding window apporach is very useful if we have huge images sizes, or if we have different resolutions across the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2e9c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T19:37:34.475373Z",
     "iopub.status.busy": "2025-07-31T19:37:34.475123Z",
     "iopub.status.idle": "2025-07-31T19:37:45.613072Z",
     "shell.execute_reply": "2025-07-31T19:37:45.612268Z"
    },
    "papermill": {
     "duration": 11.142262,
     "end_time": "2025-07-31T19:37:45.614516",
     "exception": false,
     "start_time": "2025-07-31T19:37:34.472254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cfe069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mohammad2012191/cells-types\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be453f",
   "metadata": {
    "papermill": {
     "duration": 0.00205,
     "end_time": "2025-07-31T19:37:45.619096",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.617046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1Ô∏è‚É£ Load Data & Prepare Splits\n",
    "\n",
    "**Task**: Load the `data.csv` file, extract labels, and perform stratified train/val split.\n",
    "\n",
    "**ToDo**:\n",
    "- Read the CSV file and cast `cell_type` to string\n",
    "- Extract class names and build `label2idx` dictionary\n",
    "- Perform stratified split with `train_test_split`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e903dce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T19:37:45.624410Z",
     "iopub.status.busy": "2025-07-31T19:37:45.623879Z",
     "iopub.status.idle": "2025-07-31T19:37:45.626992Z",
     "shell.execute_reply": "2025-07-31T19:37:45.626468Z"
    },
    "papermill": {
     "duration": 0.006821,
     "end_time": "2025-07-31T19:37:45.628082",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.621261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Load the CSV file and cast 'cell_type' column to string\n",
    "# TODO: Extract all unique classes and build a label2idx dictionary\n",
    "# TODO: Perform stratified train/validation split based on cell_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0bf51",
   "metadata": {
    "papermill": {
     "duration": 0.001931,
     "end_time": "2025-07-31T19:37:45.632239",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.630308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2Ô∏è‚É£ Data Preprocessing\n",
    "\n",
    "**Task**: Define image transformations and implement a custom dataset class.\n",
    "\n",
    "**ToDo**:\n",
    "- Don't use Resize\n",
    "- Apply `RandomCrop(224)` during training\n",
    "- Apply `CenterCrop(224)` during validation (best we can do, we will apply sliding window for full image in inference)\n",
    "- Normalize using ImageNet stats\n",
    "- Load images from the `images/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf2dc7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T19:37:45.637062Z",
     "iopub.status.busy": "2025-07-31T19:37:45.636863Z",
     "iopub.status.idle": "2025-07-31T19:37:45.639755Z",
     "shell.execute_reply": "2025-07-31T19:37:45.639235Z"
    },
    "papermill": {
     "duration": 0.006513,
     "end_time": "2025-07-31T19:37:45.640759",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.634246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Define training transforms (RandomCrop(224), RandomHorizontalFlip, Normalize)\n",
    "# TODO: Define validation transforms (CenterCrop(224), Normalize)\n",
    "# TODO: Implement CellDataset class:\n",
    "#       - Load image using PIL\n",
    "#       - Apply transforms\n",
    "#       - Map label string to index using label2idx\n",
    "#       - Return image and label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f58204",
   "metadata": {
    "papermill": {
     "duration": 0.001906,
     "end_time": "2025-07-31T19:37:45.644745",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.642839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3Ô∏è‚É£ Create DataLoaders\n",
    "\n",
    "**Task**: Load datasets using `DataLoader`.\n",
    "\n",
    "**ToDo**:\n",
    "- Use `shuffle=True` for training\n",
    "- Use `shuffle=False` for validation\n",
    "- Set batch size and workers\n",
    "- Define the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db6f9fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T19:37:45.649531Z",
     "iopub.status.busy": "2025-07-31T19:37:45.649305Z",
     "iopub.status.idle": "2025-07-31T19:37:45.652146Z",
     "shell.execute_reply": "2025-07-31T19:37:45.651652Z"
    },
    "papermill": {
     "duration": 0.006399,
     "end_time": "2025-07-31T19:37:45.653158",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.646759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Instantiate CellDataset for training and validation\n",
    "# TODO: Wrap both in DataLoaders (shuffle=True for train, False for val)\n",
    "# TODO: Check device availability and print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72162dc7",
   "metadata": {
    "papermill": {
     "duration": 0.001924,
     "end_time": "2025-07-31T19:37:45.657226",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.655302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4Ô∏è‚É£ Build ViT + Swin Combined Model\n",
    "\n",
    "**Task**: Create a model that extracts features from both backbones and concatenates them.\n",
    "\n",
    "**ToDo**:\n",
    "- Load ViT-B/16 (models.vit_b_16) and Swin-T (models.swin_t) with pretrained weights\n",
    "- Replace their heads with `nn.Identity` (i.e. remove the classifier heads)\n",
    "- Concatenate features and pass to a linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2845e0bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T19:37:45.662061Z",
     "iopub.status.busy": "2025-07-31T19:37:45.661824Z",
     "iopub.status.idle": "2025-07-31T19:37:45.665024Z",
     "shell.execute_reply": "2025-07-31T19:37:45.664347Z"
    },
    "papermill": {
     "duration": 0.006785,
     "end_time": "2025-07-31T19:37:45.666018",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.659233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Create VitSwinConcat class that inherits from nn.Module\n",
    "# TODO: In __init__():\n",
    "#       - Load ViT-B/16 and Swin-T from torchvision (pretrained)\n",
    "#       - Replace their classification heads with Identity()\n",
    "#       - Concatenate their outputs (768+768) and use Linear classifier\n",
    "# TODO: In forward(x):\n",
    "#       - Get features from both backbones\n",
    "#       - Concatenate along dim=1\n",
    "#       - Pass through classifier\n",
    "# TODO: Instantiate the model, define CrossEntropy loss and Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbf441d",
   "metadata": {
    "papermill": {
     "duration": 0.002021,
     "end_time": "2025-07-31T19:37:45.670105",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.668084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5Ô∏è‚É£ Train & Validate\n",
    "\n",
    "**Task**: Train the model and evaluate accuracy on the validation set.\n",
    "\n",
    "**ToDo**:\n",
    "- Write training and inference loops\n",
    "- Track training/validation loss and accuracy\n",
    "- Save the model at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5cac97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T19:37:45.675163Z",
     "iopub.status.busy": "2025-07-31T19:37:45.674774Z",
     "iopub.status.idle": "2025-07-31T19:37:45.677731Z",
     "shell.execute_reply": "2025-07-31T19:37:45.677197Z"
    },
    "papermill": {
     "duration": 0.006675,
     "end_time": "2025-07-31T19:37:45.678748",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.672073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Loop for each epoch:\n",
    "#       - Training: Zero grad ‚Üí Forward ‚Üí Loss ‚Üí Backward ‚Üí Step\n",
    "#       - Track and print average training loss\n",
    "# TODO: In evaluation:\n",
    "#       - Disable gradient, forward pass\n",
    "#       - Calculate average validation loss and accuracy\n",
    "# TODO: Save model checkpoint after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517a5e85",
   "metadata": {
    "papermill": {
     "duration": 0.002104,
     "end_time": "2025-07-31T19:37:45.684708",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.682604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6Ô∏è‚É£ Sliding-Window Inference\n",
    "\n",
    "*Task*: Write a function to classify a full image(not the cropped one) using sliding windows.\n",
    "\n",
    "*ToDo*:\n",
    "- Slide a 224√ó224 window with stride (e.g. 112)\n",
    "- Average softmax probabilities\n",
    "- Print individual patch predictions and final class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82dfc10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T19:37:45.691181Z",
     "iopub.status.busy": "2025-07-31T19:37:45.691003Z",
     "iopub.status.idle": "2025-07-31T19:37:45.694185Z",
     "shell.execute_reply": "2025-07-31T19:37:45.693555Z"
    },
    "papermill": {
     "duration": 0.007291,
     "end_time": "2025-07-31T19:37:45.695277",
     "exception": false,
     "start_time": "2025-07-31T19:37:45.687986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Define inference_sliding_window(model, img_path):\n",
    "#       - Load full-size image\n",
    "#       - Slide 224√ó224 window (stride=112)\n",
    "#       - For each patch: normalize ‚Üí predict ‚Üí store softmax\n",
    "# TODO: Average probabilities across patches\n",
    "# TODO: Print:\n",
    "#       - Probabilities for each patch\n",
    "#       - Averaged probabilities\n",
    "#       - Final predicted class for full image (argmax of average)\n",
    "\n",
    "# TODO: Call inference_sliding_window(model, \"images/5.png\") or any other test image\n",
    "\n",
    "\n",
    "# Example output:\n",
    "\n",
    "# Patch 0:  {'astro': 0.0003629255515988916, 'cort': 0.9995890259742737, 'shsy5y': 4.803628326044418e-05}\n",
    "# Patch 1:  {'astro': 0.002050854032859206, 'cort': 0.9978287816047668, 'shsy5y': 0.00012039497960358858}\n",
    "# Patch 2:  {'astro': 0.0003413844096940011, 'cort': 0.9996126294136047, 'shsy5y': 4.605785943567753e-05}\n",
    "# Patch 3:  {'astro': 0.0004650430055335164, 'cort': 0.9994938373565674, 'shsy5y': 4.10635257139802e-05}\n",
    "# ...\n",
    "# Patch 12:  {'astro': 0.00020842120284214616, 'cort': 0.9997585415840149, 'shsy5y': 3.304508572909981e-05}\n",
    "# Patch 13:  {'astro': 0.0001657304965192452, 'cort': 0.9998027682304382, 'shsy5y': 3.147909228573553e-05}\n",
    "# Patch 14:  {'astro': 0.0004247387987561524, 'cort': 0.9994537234306335, 'shsy5y': 0.00012151007103966549}\n",
    "# Average:  {'astro': 0.0005312784924171865, 'cort': 0.9994047284126282, 'shsy5y': 6.39661229797639e-05}\n",
    "# Final class:  cort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ecead4",
   "metadata": {},
   "source": [
    "## üìù Evaluation Criteria\n",
    "\n",
    "Your Cell Classification homework will be evaluated based on:\n",
    "\n",
    "1. **Implementation Correctness (70%)**\n",
    "   - Proper stratified splitting and label encoding\n",
    "   - Correct use of ViT-B/16 and Swin-T architectures\n",
    "   - Model correctly concatenates features from both backbones\n",
    "   - Sliding-window inference correctly averages predictions\n",
    "\n",
    "2. **Training and Results (20%)**\n",
    "   - Model trains and converges on validation set\n",
    "   - Accuracy and loss values are properly printed each epoch\n",
    "   - Trained weights saved successfully and reused for inference\n",
    "\n",
    "3. **Code Quality and Structure (10%)**\n",
    "   - Code follows modular structure with appropriate class/function design\n",
    "   - Clean, readable code with `ToDo` comments per cell\n",
    "   - Results are printed clearly, including per-patch and average inference\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2750748,
     "sourceId": 30201,
     "sourceType": "competition"
    },
    {
     "sourceId": 253546646,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.767104,
   "end_time": "2025-07-31T19:37:47.217395",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-31T19:37:30.450291",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
