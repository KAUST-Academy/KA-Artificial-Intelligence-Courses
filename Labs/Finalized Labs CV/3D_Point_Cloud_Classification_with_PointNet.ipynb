{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292b0176",
   "metadata": {},
   "source": [
    "![image.png](https://i.imgur.com/a3uAqnb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dbf894",
   "metadata": {},
   "source": [
    "# 3D Point Cloud Classification with PointNet\n",
    "\n",
    "This notebook demonstrates how to build a 3D point cloud classification model using **PointNet**, a groundbreaking neural network architecture designed specifically for processing 3D point cloud data.\n",
    "\n",
    "## üìå The Core Idea: PointNet Architecture\n",
    "\n",
    "PointNet revolutionized 3D deep learning by directly processing unordered point sets without requiring voxelization or mesh conversion. The key innovations include:\n",
    "\n",
    "1. **Permutation Invariance**: The network produces the same output regardless of point order\n",
    "2. **Spatial Transformation Networks (T-Nets)**: Learn optimal spatial transformations for alignment\n",
    "3. **Symmetric Aggregation**: Uses max pooling to create a global feature representation\n",
    "4. **Feature Transform**: Applies learned transformations in feature space for better alignment\n",
    "\n",
    "### **üéØ Dataset: ModelNet40**\n",
    "We'll use the ModelNet40 dataset, a standard benchmark for 3D object classification:\n",
    "- **40 object categories**: chairs, tables, airplanes, cars, etc.\n",
    "- **12,311 CAD models**: 9,843 for training, 2,468 for testing\n",
    "- **OFF file format**: Contains 3D vertices and face information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5173bf",
   "metadata": {},
   "source": [
    "\n",
    "## 0Ô∏è‚É£ 3D Data Processing\n",
    "\n",
    "### üîπ OFF File Reader\n",
    "The Object File Format (OFF) stores 3D geometry as vertices and faces. We'll extract only the vertex coordinates for point cloud processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_off_file(file_path):\n",
    "    \"\"\"Read OFF file and return vertices as numpy array.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Clean lines and remove comments\n",
    "        lines = [line.strip() for line in lines if line.strip() and not line.startswith('#')]\n",
    "        \n",
    "        if lines[0] != 'OFF':\n",
    "            return None, None\n",
    "        \n",
    "        # Parse header: number of vertices, faces, edges\n",
    "        n_vertices, n_faces, n_edges = map(int, lines[1].split())\n",
    "        \n",
    "        # Extract vertices (x, y, z coordinates)\n",
    "        vertices = []\n",
    "        for i in range(2, 2 + n_vertices):\n",
    "            vertex = list(map(float, lines[i].split()[:3]))\n",
    "            vertices.append(vertex)\n",
    "        \n",
    "        return np.array(vertices), None\n",
    "    except Exception:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607a13d",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Dataset Download and Exploration\n",
    "\n",
    "First, let's download the ModelNet40 dataset and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301839b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset and setup paths\n",
    "path = kagglehub.dataset_download(\"balraj98/modelnet40-princeton-3d-object-dataset\")\n",
    "dataset_path = Path(path)\n",
    "modelnet_path = dataset_path / \"ModelNet40\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831316e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all class directories\n",
    "classes = []\n",
    "for item in modelnet_path.iterdir():\n",
    "    if item.is_dir() and not item.name.startswith('.'):\n",
    "        train_subdir = item / \"train\"\n",
    "        if train_subdir.exists():\n",
    "            classes.append(item.name)\n",
    "\n",
    "classes.sort()\n",
    "print(f\"Found {len(classes)} classes: {classes}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9dde5",
   "metadata": {},
   "source": [
    "## This will take about 4-5 minutes to finish "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset samples\n",
    "def get_all_samples(base_path, classes, split='train'):\n",
    "    \"\"\"Load all sample file paths and their corresponding labels, filtering out corrupted files.\"\"\"\n",
    "    all_samples = []\n",
    "    corrupted_count = 0\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_path = base_path / class_name / split\n",
    "        if class_path.exists():\n",
    "            off_files = list(class_path.glob(\"*.off\"))\n",
    "            for file_path in off_files:\n",
    "                # Test if the file can be read successfully\n",
    "                vertices, _ = read_off_file(file_path)\n",
    "                if vertices is not None:\n",
    "                    all_samples.append({\n",
    "                        'file_path': file_path,\n",
    "                        'class_name': class_name,\n",
    "                        'class_id': classes.index(class_name)\n",
    "                    })\n",
    "                else:\n",
    "                    corrupted_count += 1\n",
    "    \n",
    "    print(f\"Filtered out {corrupted_count} corrupted files from {split} set\")\n",
    "    return all_samples\n",
    "\n",
    "train_samples = get_all_samples(modelnet_path, classes, split='train')\n",
    "test_samples = get_all_samples(modelnet_path, classes, split='test')\n",
    "print(f\"Train samples: {len(train_samples)}, Test samples: {len(test_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593cf764",
   "metadata": {},
   "source": [
    "A note regarding the above, this will reduce the number of classes to 33 instead of 40. This happens cause some of the files can't be read with the vertices which a PointNet works with. We will still train for 40 classes to make it consistent with the actual dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4654c9",
   "metadata": {},
   "source": [
    "### üîπ Data Visualization\n",
    "Let's visualize examples from different object categories to understand our data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_examples(samples, n_examples=6):\n",
    "    \"\"\"Plot examples from different classes showing full point clouds.\"\"\"\n",
    "    # Group samples by class and select one example from each\n",
    "    class_samples = {}\n",
    "    for sample in samples:\n",
    "        class_name = sample['class_name']\n",
    "        if class_name not in class_samples:\n",
    "            class_samples[class_name] = []\n",
    "        class_samples[class_name].append(sample)\n",
    "    \n",
    "    selected_samples = []\n",
    "    for class_name, class_sample_list in list(class_samples.items())[:n_examples]:\n",
    "        selected_samples.append(class_sample_list[0])\n",
    "    \n",
    "    # Create subplots\n",
    "    n_cols = 3\n",
    "    n_rows = (len(selected_samples) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 5 * n_rows))\n",
    "    \n",
    "    for i, sample in enumerate(selected_samples):\n",
    "        vertices, _ = read_off_file(sample['file_path'])\n",
    "        \n",
    "        if vertices is not None:\n",
    "            ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
    "            \n",
    "            # Plot all vertices with color mapping based on Z-coordinate\n",
    "            ax.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2], \n",
    "                      c=vertices[:, 2], cmap='viridis', s=1, alpha=0.7)\n",
    "            \n",
    "            ax.set_title(f\"Class: {sample['class_name']}\\n({len(vertices)} vertices)\", \n",
    "                        fontsize=12, pad=20)\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_zlabel('Z')\n",
    "            \n",
    "            # Set equal aspect ratio for better visualization\n",
    "            max_range = np.array([vertices[:, 0].max()-vertices[:, 0].min(),\n",
    "                                vertices[:, 1].max()-vertices[:, 1].min(),\n",
    "                                vertices[:, 2].max()-vertices[:, 2].min()]).max() / 2.0\n",
    "            mid_x = (vertices[:, 0].max()+vertices[:, 0].min()) * 0.5\n",
    "            mid_y = (vertices[:, 1].max()+vertices[:, 1].min()) * 0.5\n",
    "            mid_z = (vertices[:, 2].max()+vertices[:, 2].min()) * 0.5\n",
    "            \n",
    "            ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "            ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "            ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7108f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize examples from different classes\n",
    "plot_class_examples(train_samples, n_examples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6198c",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Data Preprocessing and Augmentation\n",
    "Point cloud data requires specialized preprocessing techniques to ensure consistent input format and improve model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_point_cloud(points):\n",
    "    \"\"\"Center and scale point cloud to unit sphere.\"\"\"\n",
    "    centroid = torch.mean(points, dim=0)\n",
    "    points = points - centroid\n",
    "    distances = torch.norm(points, dim=1)\n",
    "    max_distance = torch.max(distances)\n",
    "    if max_distance > 0:\n",
    "        points = points / max_distance\n",
    "    return points\n",
    "\n",
    "def random_sample_points(points, num_points=1024):\n",
    "    \"\"\"Sample fixed number of points from point cloud.\"\"\"\n",
    "    num_vertices = points.shape[0]\n",
    "    if num_vertices >= num_points:\n",
    "        # Random sampling without replacement\n",
    "        indices = torch.randperm(num_vertices)[:num_points]\n",
    "        return points[indices]\n",
    "    else:\n",
    "        # Duplicate points if we have fewer than needed\n",
    "        repeat_factor = (num_points // num_vertices) + 1\n",
    "        repeated_points = points.repeat(repeat_factor, 1)\n",
    "        indices = torch.randperm(repeated_points.shape[0])[:num_points]\n",
    "        return repeated_points[indices]\n",
    "\n",
    "def random_rotation(points):\n",
    "    \"\"\"Apply random rotation around Y-axis for data augmentation.\"\"\"\n",
    "    angle = torch.rand(1) * 2 * torch.pi\n",
    "    cos_angle = torch.cos(angle)\n",
    "    sin_angle = torch.sin(angle)\n",
    "    rotation_matrix = torch.tensor([\n",
    "        [cos_angle, 0, sin_angle],\n",
    "        [0, 1, 0],\n",
    "        [-sin_angle, 0, cos_angle]\n",
    "    ], dtype=points.dtype)\n",
    "    return torch.matmul(points, rotation_matrix.T)\n",
    "\n",
    "def add_noise(points, noise_std=0.01):\n",
    "    \"\"\"Add Gaussian noise for data augmentation.\"\"\"\n",
    "    noise = torch.randn_like(points) * noise_std\n",
    "    return points + noise\n",
    "\n",
    "class PointCloudTransform:\n",
    "    \"\"\"Comprehensive point cloud preprocessing pipeline.\"\"\"\n",
    "    def __init__(self, num_points=1024, normalize=True, augment=True, noise_std=0.01):\n",
    "        self.num_points = num_points\n",
    "        self.normalize = normalize\n",
    "        self.augment = augment\n",
    "        self.noise_std = noise_std\n",
    "    \n",
    "    def __call__(self, points):\n",
    "        # Sample fixed number of points\n",
    "        points = random_sample_points(points, self.num_points)\n",
    "        \n",
    "        # Normalize to unit sphere\n",
    "        if self.normalize:\n",
    "            points = normalize_point_cloud(points)\n",
    "        \n",
    "        # Apply augmentations during training\n",
    "        if self.augment:\n",
    "            if torch.rand(1) > 0.5:\n",
    "                points = random_rotation(points)\n",
    "            if torch.rand(1) > 0.5:\n",
    "                points = add_noise(points, self.noise_std)\n",
    "        \n",
    "        return points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aacea9",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ PointNet Architecture Implementation\n",
    "\n",
    "### üîπ Spatial Transformer Networks (T-Nets)\n",
    "T-Nets learn optimal spatial transformations to align point clouds, making the model more robust to rotations and translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db61df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TNet(nn.Module):\n",
    "    \"\"\"Spatial Transformer Network for learning optimal transformations.\"\"\"\n",
    "    def __init__(self, k=3):\n",
    "        super(TNet, self).__init__()\n",
    "        self.k = k\n",
    "        \n",
    "        # Convolutional layers for feature extraction\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        \n",
    "        # Fully connected layers for transformation matrix prediction\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k * k)\n",
    "        \n",
    "        # Batch normalization for stable training\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Feature extraction\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Global max pooling\n",
    "        x = torch.max(x, 2)[0]\n",
    "        \n",
    "        # Predict transformation matrix\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # Add identity matrix for stable training\n",
    "        identity = torch.eye(self.k, device=x.device).view(1, self.k * self.k).repeat(batch_size, 1)\n",
    "        x = x + identity\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259c715",
   "metadata": {},
   "source": [
    "### üîπ PointNet Encoder\n",
    "The encoder extracts global features from the point cloud while maintaining permutation invariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d72de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetEncoder(nn.Module):\n",
    "    \"\"\"PointNet encoder for feature extraction from point clouds.\"\"\"\n",
    "    def __init__(self, global_feat=True, feature_transform=True):\n",
    "        super(PointNetEncoder, self).__init__()\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        \n",
    "        # Input transformation network\n",
    "        self.input_transform = TNet(k=3)\n",
    "        \n",
    "        # Feature transformation network (optional)\n",
    "        if self.feature_transform:\n",
    "            self.feature_transform_net = TNet(k=64)\n",
    "        \n",
    "        # Point-wise feature extraction\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, num_points, _ = x.size()\n",
    "        \n",
    "        # Apply input transformation\n",
    "        trans_input = self.input_transform(x.transpose(2, 1))\n",
    "        x = torch.bmm(x, trans_input)\n",
    "        x = x.transpose(2, 1)\n",
    "        \n",
    "        # First feature extraction\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # Apply feature transformation if enabled\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.feature_transform_net(x)\n",
    "            x = x.transpose(2, 1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2, 1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "        \n",
    "        # Continue feature extraction\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        \n",
    "        # Global feature aggregation via max pooling\n",
    "        x = torch.max(x, 2)[0]\n",
    "        \n",
    "        if self.global_feat:\n",
    "            return x, trans_input, trans_feat\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, num_points)\n",
    "            return torch.cat([pointfeat, x], 1), trans_input, trans_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138af10",
   "metadata": {},
   "source": [
    "### üîπ PointNet Classifier\n",
    "The complete classification model combining encoder and classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetClassifier(nn.Module):\n",
    "    \"\"\"Complete PointNet model for 3D point cloud classification.\"\"\"\n",
    "    def __init__(self, num_classes=40, dropout=0.3, feature_transform=True):\n",
    "        super(PointNetClassifier, self).__init__()\n",
    "        self.feature_transform = feature_transform\n",
    "        \n",
    "        # PointNet encoder\n",
    "        self.encoder = PointNetEncoder(global_feat=True, feature_transform=feature_transform)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, trans_input, trans_feat = self.encoder(x)\n",
    "        \n",
    "        # Classification layers\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1), trans_input, trans_feat\n",
    "\n",
    "def feature_transform_regularizer(trans):\n",
    "    \"\"\"Regularization term for feature transformation matrix.\"\"\"\n",
    "    d = trans.size()[1]\n",
    "    identity = torch.eye(d, device=trans.device)\n",
    "    identity = identity.unsqueeze(0).repeat(trans.size()[0], 1, 1)\n",
    "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2, 1)) - identity, dim=(1, 2)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1f32c",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Dataset Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a13ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNet40Dataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for ModelNet40 point cloud data.\"\"\"\n",
    "    def __init__(self, samples, transform=None, num_points=1024):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "        self.num_points = num_points\n",
    "        self.class_names = sorted(list(set(sample['class_name'] for sample in samples)))\n",
    "        self.num_classes = len(self.class_names)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        vertices, _ = read_off_file(sample['file_path'])\n",
    "        \n",
    "        # Handle corrupted files\n",
    "        if vertices is None:\n",
    "            vertices = np.random.randn(self.num_points, 3).astype(np.float32)\n",
    "        \n",
    "        vertices = torch.FloatTensor(vertices)\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            vertices = self.transform(vertices)\n",
    "        else:\n",
    "            vertices = random_sample_points(vertices, self.num_points)\n",
    "            vertices = normalize_point_cloud(vertices)\n",
    "        \n",
    "        label = torch.LongTensor([sample['class_id']])[0]\n",
    "        return vertices, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974176f",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Training Setup and Execution\n",
    "\n",
    "### üîπ Hyperparameters and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb162f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "NUM_POINTS = 1024\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 15 \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data transformations\n",
    "train_transform = PointCloudTransform(NUM_POINTS, True, True, 0.01)  # With augmentation\n",
    "test_transform = PointCloudTransform(NUM_POINTS, True, False)        # Without augmentation\n",
    "\n",
    "# Create datasets and data loaders\n",
    "train_dataset = ModelNet40Dataset(train_samples, transform=train_transform, num_points=NUM_POINTS)\n",
    "test_dataset = ModelNet40Dataset(test_samples, transform=test_transform, num_points=NUM_POINTS)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4,\n",
    "                         pin_memory=True if torch.cuda.is_available() else False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4,\n",
    "                        pin_memory=True if torch.cuda.is_available() else False)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = PointNetClassifier(num_classes=len(classes), dropout=0.3, feature_transform=True).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")\n",
    "print(f\"Number of classes: {len(classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24149cea",
   "metadata": {},
   "source": [
    "### üîπ Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, reg_weight=0.001):\n",
    "    \"\"\"Train the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    train_bar = tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_bar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred, trans_input, trans_feat = model(data)\n",
    "        loss = criterion(pred, target)\n",
    "        \n",
    "        # Add regularization for feature transformation\n",
    "        if trans_feat is not None:\n",
    "            reg_loss = feature_transform_regularizer(trans_feat)\n",
    "            loss += reg_weight * reg_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total_loss += loss.item()\n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct += pred_choice.eq(target.data).cpu().sum()\n",
    "        total += target.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{100. * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test_epoch(model, test_loader, criterion, device):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(test_loader, desc='Testing')\n",
    "        \n",
    "        for data, target in test_bar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            pred, _, _ = model(data)\n",
    "            loss = criterion(pred, target)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            pred_choice = pred.data.max(1)[1]\n",
    "            correct += pred_choice.eq(target.data).cpu().sum()\n",
    "            total += target.size(0)\n",
    "            \n",
    "            all_preds.extend(pred_choice.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            \n",
    "            test_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100. * correct / total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy, all_preds, all_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef32d6a",
   "metadata": {},
   "source": [
    "### üîπ Main Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88342ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "best_test_acc = 0\n",
    "best_model_state = None\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    # Train and evaluate\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc, _, _ = test_epoch(model, test_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save best model\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "    \n",
    "    # Record history\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "    print(f'Best Test Acc: {best_test_acc:.2f}%')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f'\\nTraining completed in {total_time:.2f} seconds')\n",
    "print(f'Best test accuracy: {best_test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ecee97",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Results Analysis and Visualization\n",
    "\n",
    "### üîπ Training Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5bd241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training progress\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(train_losses, label='Train Loss', color='blue')\n",
    "ax1.plot(test_losses, label='Test Loss', color='red')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Test Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(train_accuracies, label='Train Accuracy', color='blue')\n",
    "ax2.plot(test_accuracies, label='Test Accuracy', color='red')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Test Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc47275",
   "metadata": {},
   "source": [
    "### üîπ Final Evaluation with Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56035aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and perform final evaluation\n",
    "model.load_state_dict(best_model_state)\n",
    "final_test_loss, final_test_acc, final_preds, final_targets = test_epoch(model, test_loader, criterion, device)\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n",
    "print(f\"Final Test Loss: {final_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65bb30",
   "metadata": {},
   "source": [
    "### üîπ Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5cadc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot confusion matrix\n",
    "cm = confusion_matrix(final_targets, final_preds)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd784fd",
   "metadata": {},
   "source": [
    "### üîπ Per-Class Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class accuracy analysis\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "plt.figure(figsize=(15, 6))\n",
    "bars = plt.bar(class_names, per_class_acc * 100)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Per-Class Accuracy')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Color code bars based on performance\n",
    "for i, bar in enumerate(bars):\n",
    "    acc = per_class_acc[i] * 100\n",
    "    if acc >= 80:\n",
    "        bar.set_color('green')\n",
    "    elif acc >= 60:\n",
    "        bar.set_color('orange')\n",
    "    else:\n",
    "        bar.set_color('red')\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(final_targets, final_preds, target_names=class_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae0dbb",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Model Inference and Prediction Visualization\n",
    "\n",
    "### üîπ Single Object Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13bdfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_object(model, vertices, transform, class_names, device):\n",
    "    \"\"\"Predict class for a single 3D object.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(vertices, np.ndarray):\n",
    "            vertices = torch.FloatTensor(vertices)\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        processed_points = transform(vertices)\n",
    "        batch_points = processed_points.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get prediction\n",
    "        pred, _, _ = model(batch_points)\n",
    "        pred_probs = torch.exp(pred)\n",
    "        top_prob, top_class = torch.max(pred_probs, 1)\n",
    "        \n",
    "        predicted_class = class_names[top_class.item()]\n",
    "        confidence = top_prob.item()\n",
    "        \n",
    "        return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda16fe",
   "metadata": {},
   "source": [
    "### üîπ Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b882fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_vs_actual(model, test_samples, transform, class_names, device, n_examples=6):\n",
    "    \"\"\"Visualize model predictions on test samples.\"\"\"\n",
    "    # Sample valid test examples\n",
    "    selected_samples = []\n",
    "    max_attempts = n_examples * 3\n",
    "    attempts = 0\n",
    "    \n",
    "    while len(selected_samples) < n_examples and attempts < max_attempts:\n",
    "        sample = random.choice(test_samples)\n",
    "        vertices, _ = read_off_file(sample['file_path'])\n",
    "        \n",
    "        if vertices is not None:\n",
    "            selected_samples.append(sample)\n",
    "        attempts += 1\n",
    "    \n",
    "    if len(selected_samples) == 0:\n",
    "        print(\"No valid samples could be loaded for visualization\")\n",
    "        return\n",
    "    \n",
    "    actual_n_examples = len(selected_samples)\n",
    "    n_cols = 3\n",
    "    n_rows = (actual_n_examples + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 6 * n_rows))\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for i, sample in enumerate(selected_samples):\n",
    "        vertices, _ = read_off_file(sample['file_path'])\n",
    "        \n",
    "        # Get prediction\n",
    "        predicted_class, confidence = predict_single_object(\n",
    "            model, vertices, transform, class_names, device\n",
    "        )\n",
    "        \n",
    "        actual_class = sample['class_name']\n",
    "        is_correct = predicted_class == actual_class\n",
    "        if is_correct:\n",
    "            correct_predictions += 1\n",
    "        \n",
    "        # Plot 3D visualization\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
    "        ax.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2], \n",
    "                  c=vertices[:, 2], cmap='viridis', s=1, alpha=0.7)\n",
    "        \n",
    "        # Create title with prediction results\n",
    "        title_color = 'green' if is_correct else 'red'\n",
    "        title = f\"Actual: {actual_class}\\nPredicted: {predicted_class}\\nConfidence: {confidence:.3f}\"\n",
    "        \n",
    "        ax.set_title(title, fontsize=11, pad=20, color=title_color, weight='bold')\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        \n",
    "        # Set equal aspect ratio\n",
    "        max_range = np.array([vertices[:, 0].max()-vertices[:, 0].min(),\n",
    "                            vertices[:, 1].max()-vertices[:, 1].min(),\n",
    "                            vertices[:, 2].max()-vertices[:, 2].min()]).max() / 2.0\n",
    "        mid_x = (vertices[:, 0].max()+vertices[:, 0].min()) * 0.5\n",
    "        mid_y = (vertices[:, 1].max()+vertices[:, 1].min()) * 0.5\n",
    "        mid_z = (vertices[:, 2].max()+vertices[:, 2].min()) * 0.5\n",
    "        \n",
    "        ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "        ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "        ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "    \n",
    "    plt.suptitle(f'Actual vs Predicted Classes ({correct_predictions}/{actual_n_examples} correct)', \n",
    "                fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Prediction accuracy on sample: {correct_predictions}/{actual_n_examples} = {100*correct_predictions/actual_n_examples:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad41b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbcef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair',\n",
    "    'cone', 'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box',\n",
    "    'guitar', 'keyboard', 'lamp', 'laptop', 'mantel', 'monitor', 'night_stand',\n",
    "    'person', 'piano', 'plant', 'radio', 'range_hood', 'sink', 'sofa', 'stairs',\n",
    "    'stool', 'table', 'tent', 'toilet', 'tv_stand', 'vase', 'wardrobe', 'xbox'\n",
    "] # This is a dirty fix to just get the actual classes back even though we only have 33 that we can actually predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visualizing predictions vs actual classes...\")\n",
    "plot_predictions_vs_actual(model, test_samples, test_transform, classes, device, n_examples=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd917437",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Model Saving and Loading\n",
    "\n",
    "### üîπ Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e4ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete model information\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'num_classes': train_dataset.num_classes,\n",
    "    'class_names': class_names,\n",
    "    'best_test_acc': best_test_acc,\n",
    "    'num_points': NUM_POINTS,\n",
    "    'embed_size': 512,\n",
    "    'hidden_size': 256,\n",
    "    'num_decoder_layers': 3,\n",
    "    'training_history': {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'test_losses': test_losses,\n",
    "        'test_accuracies': test_accuracies\n",
    "    }\n",
    "}, 'pointnet_modelnet40.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best test accuracy achieved: {best_test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43df7ead",
   "metadata": {},
   "source": [
    "### üîπ Load and Use Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb91ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pointnet_model(model_path, device='cpu'):\n",
    "    \"\"\"Load a saved PointNet model for inference.\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Recreate model architecture\n",
    "    model = PointNetClassifier(\n",
    "        num_classes=checkpoint['num_classes'], \n",
    "        dropout=0.3, \n",
    "        feature_transform=True\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load trained weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    return model, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# loaded_model, checkpoint = load_pointnet_model('pointnet_modelnet40.pth', device)\n",
    "# class_names = checkpoint['class_names']\n",
    "# print(f\"Loaded model with {checkpoint['best_test_acc']:.2f}% test accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eca5941",
   "metadata": {},
   "source": [
    "\n",
    "## 9Ô∏è‚É£ Conclusion and Future Improvements\n",
    "\n",
    "\n",
    "### **üìù Exercises for Further Exploration**\n",
    "\n",
    "- Experiment with different numbers of points (512, 2048, 4096)\n",
    "- Try different aggregation functions (mean, attention-based)\n",
    "- Add more layers to the classification head\n",
    "- Add more sophisticated augmentations (scaling, jittering)\n",
    "- Look for a different dataset and see what you get\n",
    "\n",
    "### **üìö Further Reading**\n",
    "- Original PointNet paper: \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\"\n",
    "- PointNet++: \"PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space\"\n",
    "- Survey paper: \"Deep Learning for 3D Point Clouds: A Survey\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad32259",
   "metadata": {},
   "source": [
    "### Contributed by: Ali Habibullah"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
