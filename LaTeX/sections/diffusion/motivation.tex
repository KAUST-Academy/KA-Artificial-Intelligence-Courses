\begin{frame}[allowframebreaks]{Diffusion Models: Motivation}
    \begin{itemize}
        \item \textbf{The Journey of Generative Modeling:}
        \begin{itemize}
            \item Early successes: GANs and VAEs enabled impressive image synthesis and data generation.
            \item \textcolor{red}{Drawbacks:} 
            \begin{itemize}
                \item GANs: Training instability, mode collapse, and sensitivity to hyperparameters.
                \item VAEs: Blurry outputs and limited expressiveness.
            \end{itemize}
            \item \textcolor{blue}{Key Challenge:} Achieving both high sample quality and stable, reliable training.
        \end{itemize}
        \item \textbf{Where do we go from here?}
        \begin{itemize}
            \item Need for models that are robust, interpretable, and capable of generating diverse, high-fidelity samples.
        \end{itemize}

\framebreak

        \item \textbf{Enter Diffusion Models:}
        \begin{itemize}
            \item Inspired by thermodynamics, diffusion models gradually transform noise into data.
            \item \textcolor[rgb]{0,0.6,0}{Highlights:} 
            \begin{itemize}
                \item Simple training objective
                \item Stable optimization
                \item State-of-the-art sample quality
                \item Probabilistic and interpretable framework
            \end{itemize}
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Diffusion Models: Learning Outcomes}
    After this lecture, you will be able to:
    \begin{itemize}
        \item Explain the core principles behind diffusion-based generative models.
        \item Understand the forward and reverse processes in diffusion.
        \item Relate the training objective to variational inference and ELBO.
        \item Describe model architectures used in state-of-the-art diffusion models.
        \item Analyze and critique applications like GLIDE, DALLÂ·E 2, Imagen, etc.
    \end{itemize}
\end{frame}