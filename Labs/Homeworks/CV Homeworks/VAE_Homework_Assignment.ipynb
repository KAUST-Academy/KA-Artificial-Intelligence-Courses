{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zemWtDr8gVOf"
   },
   "source": [
    "![Banner](https://i.imgur.com/a3uAqnb.png)\n",
    "\n",
    "# Variational Autoencoder for Image Attribute Manipulation - Homework Assignment\n",
    "\n",
    "In this homework, you will implement a **Conditional Variational Autoencoder (CVAE)** using PyTorch to perform image attribute manipulation on the CelebA dataset. This involves learning disentangled representations and using them to modify specific facial attributes like adding glasses or changing hair color.\n",
    "\n",
    "## üìå Project Overview\n",
    "- **Task**: Image attribute manipulation using CVAE\n",
    "- **Architecture**: Conditional Variational Autoencoder with encoder-decoder structure\n",
    "- **Dataset**: CelebA (200K+ celebrity face images with 40 attribute annotations)\n",
    "- **Goal**: Learn to encode/decode images while controlling specific attributes\n",
    "\n",
    "## üìö Learning Objectives\n",
    "By completing this assignment, you will:\n",
    "- Implement a Conditional Variational Autoencoder architecture\n",
    "- Work with facial attribute datasets and preprocessing\n",
    "- Learn about latent space manipulation for attribute control\n",
    "- Apply reparameterization trick and VAE loss functions\n",
    "- Evaluate generative models through reconstruction and manipulation quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Dataset Setup and Preprocessing\n",
    "\n",
    "**Task**: Download and preprocess the CelebA dataset with proper transformations.\n",
    "\n",
    "**Requirements**:\n",
    "- Download CelebA dataset using kagglehub\n",
    "- Create custom dataset class for loading images and attributes\n",
    "- Implement proper image transformations and normalization\n",
    "- Set up data loaders for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import all necessary libraries\n",
    "\n",
    "# TODO: Download CelebA dataset using kagglehub\n",
    "#       - Use kagglehub.dataset_download(\"jessicali9530/celeba-dataset\")\n",
    "\n",
    "# TODO: Create CelebADataset class inheriting from Dataset:\n",
    "#       In __init__(self, root_dir, attr_file, transform=None, max_samples=None):\n",
    "#       - Read attributes CSV file using pandas\n",
    "#       - Store image directory path and transforms\n",
    "#       - Get attribute names (excluding image_id column)\n",
    "#       - Optionally limit dataset size with max_samples\n",
    "#       \n",
    "#       In __len__(self):\n",
    "#       - Return length of attribute dataframe\n",
    "#       \n",
    "#       In __getitem__(self, idx):\n",
    "#       - Load image using PIL and convert to RGB\n",
    "#       - Get corresponding attributes and convert from [-1,1] to [0,1]\n",
    "#       - Apply transforms if provided\n",
    "#       - Return image tensor and attribute tensor\n",
    "\n",
    "# TODO: Define image transformations:\n",
    "#       - Resize to (64, 64)\n",
    "#       - Convert to tensor\n",
    "#       - Normalize to [-1, 1] range using (0.5, 0.5, 0.5) mean and std\n",
    "\n",
    "# TODO: Set up dataset paths and create dataset instance\n",
    "# TODO: Create DataLoader with appropriate batch size and shuffling\n",
    "# TODO: Test the dataloader and print dataset information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Implement Conditional Variational Autoencoder\n",
    "\n",
    "**Task**: Build a CVAE architecture that can encode images conditioned on attributes and decode them back.\n",
    "\n",
    "**Requirements**:\n",
    "- Create encoder network that takes image and attributes as input\n",
    "- Implement reparameterization trick for sampling latent variables\n",
    "- Build decoder that reconstructs images from latent code and attributes\n",
    "- Add proper batch normalization and activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create CVAE class inheriting from nn.Module:\n",
    "#       In __init__(self, input_channels=3, input_size=64, hidden_dim=512, latent_dim=128, condition_dim=40):\n",
    "#       \n",
    "#       Encoder components:\n",
    "#       - Convolutional layers for feature extraction from images\n",
    "#       - Condition embedding network for processing attributes\n",
    "#       - Fully connected layers to combine image features with conditions\n",
    "#       - Separate linear layers for mean (fc_mu) and log variance (fc_logvar)\n",
    "#       \n",
    "#       Decoder components:\n",
    "#       - Fully connected layers that take latent code + embedded conditions\n",
    "#       - Transposed convolutional layers for upsampling back to image size\n",
    "#       - Proper batch normalization and activation functions\n",
    "\n",
    "# TODO: Implement encode(self, x, c) method:\n",
    "#       - Extract features from input image x using convolutional layers\n",
    "#       - Embed condition vector c using condition embedding network\n",
    "#       - Concatenate image features with embedded conditions\n",
    "#       - Pass through encoder fully connected layers\n",
    "#       - Return mu and logvar for latent distribution\n",
    "\n",
    "# TODO: Implement reparameterize(self, mu, logvar) method:\n",
    "#       - Use reparameterization trick for differentiable sampling\n",
    "#       - During training: sample epsilon from standard normal, return mu + epsilon * std\n",
    "#       - During inference: return mu directly\n",
    "\n",
    "# TODO: Implement decode(self, z, c) method:\n",
    "#       - Embed condition vector c\n",
    "#       - Concatenate latent vector z with embedded conditions\n",
    "#       - Pass through decoder fully connected layers\n",
    "#       - Reshape and pass through transposed convolutional layers\n",
    "#       - Return reconstructed image\n",
    "\n",
    "# TODO: Implement forward(self, x, c) method:\n",
    "#       - Encode input to get mu and logvar\n",
    "#       - Sample latent vector using reparameterization\n",
    "#       - Decode latent vector with conditions\n",
    "#       - Return reconstruction, mu, and logvar\n",
    "\n",
    "# TODO: Implement sample(self, c, num_samples=1, device='cpu') method:\n",
    "#       - Sample latent vectors from prior (standard normal)\n",
    "#       - Decode with given conditions to generate new images\n",
    "\n",
    "# TODO: Create CVAE loss function:\n",
    "#       - Reconstruction loss (MSE between original and reconstructed)\n",
    "#       - KL divergence loss for regularizing latent space\n",
    "#       - Combine with beta weighting for Œ≤-VAE\n",
    "#       - Return total loss, reconstruction loss, and KL loss separately\n",
    "\n",
    "# TODO: Initialize model and move to device\n",
    "# TODO: Test model with sample batch to verify shapes and functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Training Configuration and Loop\n",
    "\n",
    "**Task**: Set up training parameters and implement the main training loop with proper scheduling.\n",
    "\n",
    "**Requirements**:\n",
    "- Configure training hyperparameters including Œ≤-VAE scheduling\n",
    "- Implement training loop with loss tracking and visualization\n",
    "- Save model checkpoints and sample images during training\n",
    "- Monitor reconstruction quality and loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up training configuration\n",
    "\n",
    "# TODO: Initialize optimizer (recommend AdamW) and any learning rate schedulers\n",
    "\n",
    "# TODO: Create training history tracking:\n",
    "#       - Lists for total loss, reconstruction loss, KL loss\n",
    "#       - Beta values for Œ≤-VAE scheduling\n",
    "\n",
    "# TODO: Implement get_beta(epoch, config) function:\n",
    "#       - Start with low beta value and gradually increase\n",
    "#       - Use warmup period for stable training\n",
    "\n",
    "# TODO: Create save_sample_images function:\n",
    "#       - Generate reconstructions and new samples during training\n",
    "#       - Save visualization grids showing original, reconstructed, and generated images\n",
    "#       - Display progress over epochs\n",
    "\n",
    "# TODO: Implement main training loop:\n",
    "#       For each epoch:\n",
    "#       - Set model to training mode\n",
    "#       - For each batch:\n",
    "#         * Move data to device\n",
    "#         * Zero gradients\n",
    "#         * Forward pass through CVAE\n",
    "#         * Calculate total loss (reconstruction + Œ≤ * KL)\n",
    "#         * Backward pass and optimize\n",
    "#         * Track running losses\n",
    "#       - Update beta value for Œ≤-VAE\n",
    "#       - Save sample images at intervals\n",
    "#       - Save model checkpoints\n",
    "#       - Print epoch statistics\n",
    "\n",
    "# TODO: Plot training curves:\n",
    "#       - Total loss, reconstruction loss, and KL loss over epochs\n",
    "#       - Beta scheduling curve\n",
    "#       - Save plots and show progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Attribute Manipulation and Evaluation\n",
    "\n",
    "**Task**: Implement attribute manipulation functionality and evaluate the model's performance.\n",
    "\n",
    "**Requirements**:\n",
    "- Create functions to manipulate specific facial attributes\n",
    "- Test manipulation on various attributes (smiling, glasses, hair color, etc.)\n",
    "- Visualize before/after comparisons for attribute changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define important attributes for manipulation:\n",
    "#       - Create dictionary mapping attribute names to indices\n",
    "#       - Include key attributes like: Smiling, Male, Young, Eyeglasses, \n",
    "#         Blond_Hair, Black_Hair, Mustache, Bald, Wearing_Lipstick, etc.\n",
    "\n",
    "# TODO: Implement manipulate_single_attribute function:\n",
    "#       - Take original image, attributes, target attribute, and desired value\n",
    "#       - Encode image to latent space using original attributes\n",
    "#       - Modify the target attribute in the condition vector\n",
    "#       - Decode with modified attributes to get manipulated image\n",
    "#       - Return the manipulated result\n",
    "\n",
    "# TODO: Create show_attribute_manipulation function:\n",
    "#       - Find examples with and without specific attributes\n",
    "#       - Show before/after comparisons for adding/removing attributes\n",
    "#       - Create clean visualizations with proper titles and labels\n",
    "#       - Save manipulation results for analysis\n",
    "\n",
    "# TODO: Test attribute manipulation on key attributes:\n",
    "#       - Smiling: add/remove smiles\n",
    "#       - Eyeglasses: add/remove glasses\n",
    "#       - Male/Female: gender manipulation\n",
    "#       - Hair attributes: color and style changes\n",
    "#       - Facial hair: mustache, goatee manipulation\n",
    "\n",
    "\n",
    "# TODO: Generate final results visualization:\n",
    "#       - Grid showing multiple attribute manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Evaluation Criteria\n",
    "\n",
    "Your VAE homework will be evaluated based on:\n",
    "\n",
    "1. **Implementation Correctness (35%)**\n",
    "   - Proper CVAE architecture with encoder/decoder\n",
    "   - Correct implementation of reparameterization trick\n",
    "   - Working VAE loss function with KL divergence\n",
    "   - Functional attribute manipulation pipeline\n",
    "\n",
    "2. **Training and Results (30%)**\n",
    "   - Model trains successfully without collapse\n",
    "   - Successful attribute manipulations on key attributes\n",
    "   - Proper Œ≤-VAE scheduling and convergence\n",
    "\n",
    "3. **Code Quality and Analysis (35%)**\n",
    "   - Clean, readable code with comprehensive comments\n",
    "   - Proper visualization of results and training progress"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
