\begin{frame}{SSL: Learning Outcomes}
    By the end of this session, you should be able to:
    \begin{itemize}
        % \setlength{\itemsep}{-0.5em}
        \item \textbf{Explain} the data efficiency imperative and theoretical motivations behind self-supervised learning (SSL).
        \item \textbf{Identify} key cognitive principles that inspire self-supervision in machine learning.
        % \item \textbf{Compare} reconstructive, predictive, and contrastive pretext tasks used in SSL.
        % \item \textbf{Implement and evaluate} Denoising Autoencoders and Context Encoders for representation learning.
        % \item \textbf{Formulate} the InfoNCE loss and \textbf{train} Contrastive Predictive Coding (CPC) models.
        \item \textbf{Describe} Instance Discrimination and \textbf{implement} the Momentum Contrast (MoCo) framework.
        \item \textbf{Critically assess} pretext tasks such as rotation prediction, relative patch prediction, and view prediction.
    \end{itemize}
\end{frame}