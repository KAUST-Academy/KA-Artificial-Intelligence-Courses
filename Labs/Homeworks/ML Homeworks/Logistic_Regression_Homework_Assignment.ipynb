{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB4ruSrXUn31"
      },
      "source": [
        "![image.png](https://i.imgur.com/a3uAqnb.png)\n",
        "\n",
        "# Logistic Regression for Titanic Survival Prediction - Homework Assignment\n",
        "\n",
        "In this homework, you will implement a **Logistic Regression classifier** to predict passenger survival on the Titanic. This project will help you understand the fundamentals of classification using logistic regression.\n",
        "\n",
        "## üìå Project Overview\n",
        "- **Task**: Predict passenger survival on the Titanic\n",
        "- **Algorithm**: Logistic Regression for binary classification\n",
        "- **Dataset**: Titanic passenger dataset (provided)\n",
        "- **Goal**: Build an accurate classification model using scikit-learn\n",
        "\n",
        "## üìö Learning Objectives\n",
        "By completing this assignment, you will:\n",
        "- Understand logistic regression for binary classification problems\n",
        "- Learn data preprocessing and feature engineering techniques\n",
        "- Practice exploratory data analysis (EDA)\n",
        "- Implement feature selection and model evaluation\n",
        "- Learn about classification metrics and model performance\n",
        "- Identify the most important features for survival prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Initial Setup and Library Installation\n",
        "\n",
        "**Task**: Set up the environment and install necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neIi6I4jQirE"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Library Installation (if needed)\n",
        "\n",
        "**Task**: Install required libraries for the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuEIiUJ5T7rv"
      },
      "outputs": [],
      "source": [
        "# Incase you run this notebook outside colab (where the libraries aren't already pre-installed)\n",
        "\n",
        "# %pip install numpy\n",
        "# %pip install pandas\n",
        "# %pip install matplotlib\n",
        "# %pip install seaborn\n",
        "# %pip install scikit-learn\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Import Libraries and Configuration\n",
        "\n",
        "**Task**: Import all necessary libraries and set up configuration parameters.\n",
        "\n",
        "**Requirements**:\n",
        "- Import data processing libraries (pandas, numpy)\n",
        "- Import visualization libraries (matplotlib, seaborn)\n",
        "- Import scikit-learn modules for preprocessing and modeling\n",
        "- Set random seeds for reproducibility\n",
        "- Configure display options for better data visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure pandas display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "# Configure matplotlib\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Data Loading and Initial Exploration\n",
        "\n",
        "**Task**: Load the Titanic dataset and perform initial exploration.\n",
        "\n",
        "**Requirements**:\n",
        "- Download and load the dataset\n",
        "- Display basic information about the data\n",
        "- Check data types and structure\n",
        "- Identify the target variable and features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkobY1tMpI8W",
        "outputId": "abd4a602-bf64-47eb-a49f-01daa29749db"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"yasserh/titanic-dataset\") # Titanic-Dataset.csv\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load the Titanic dataset\n",
        "titanic_data = None\n",
        "\n",
        "# TODO: Display basic information about the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Exploratory Data Analysis (EDA)\n",
        "\n",
        "**Task**: Perform comprehensive exploratory data analysis to understand the data.\n",
        "\n",
        "**Requirements**:\n",
        "- Examine data structure and missing values\n",
        "- Analyze the distribution of the target variable\n",
        "- Explore relationships between features and survival\n",
        "- Create visualizations to understand data patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Display first few rows of the dataset\n",
        "\n",
        "# TODO: Get basic information about the dataset (shape, data types)\n",
        "\n",
        "# TODO: Check for missing values\n",
        "\n",
        "# TODO: Display statistical summary of numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Analyze the target variable distribution (Survived)\n",
        "\n",
        "# TODO: Create visualizations for survival distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Explore survival rates by different categorical features (Sex, Pclass, Embarked)\n",
        "\n",
        "# TODO: Create  plots to visualize survival rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Analyze numerical features (Age, Fare, SibSp, Parch)\n",
        "\n",
        "# TODO: Create histograms for numerical features\n",
        "\n",
        "# TODO: Examine survival rates across different age groups and fare ranges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Data Preprocessing and Feature Engineering\n",
        "\n",
        "**Task**: Clean and prepare the data for logistic regression modeling.\n",
        "\n",
        "**Requirements**:\n",
        "- Handle missing values appropriately\n",
        "- Encode categorical variables\n",
        "- Create new features if beneficial\n",
        "- Scale numerical features if necessary\n",
        "- Select relevant features for modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create a copy of the dataset for preprocessing\n",
        "titanic_processed = titanic_data.copy()\n",
        "\n",
        "# TODO: Handle missing values\n",
        "# - Fill missing Age values (consider using median or mean)\n",
        "# - Fill missing Embarked values (consider using mode)\n",
        "# - Handle missing Cabin values (consider creating a binary feature)\n",
        "\n",
        "# TODO: Feature engineering\n",
        "# - Create FamilySize feature from SibSp and Parch\n",
        "# - Create IsAlone feature\n",
        "# - Create Age groups or Fare groups if beneficial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Encode categorical variables\n",
        "# - Convert Sex to numerical values\n",
        "# - Encode Embarked using appropriate method\n",
        "# - Handle any other categorical features\n",
        "\n",
        "# TODO: Drop irrelevant columns (Name, PassengerId, Ticket, etc.)\n",
        "\n",
        "# TODO: Verify the processed dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Ô∏è‚É£ Feature Selection and Data Splitting\n",
        "\n",
        "**Task**: Select the most relevant features and split the data for training and testing.\n",
        "\n",
        "**Requirements**:\n",
        "- Separate features (X) from target variable (y)\n",
        "- Split data into training and testing sets (80:20 ratio)\n",
        "- Apply feature scaling if necessary\n",
        "- Ensure no data leakage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Separate features from target variable\n",
        "# X = features, y = target (Survived)\n",
        "\n",
        "# TODO: Split the data into training and testing sets (80:20 split)\n",
        "\n",
        "# TODO: Apply feature scaling if necessary (StandardScaler)\n",
        "\n",
        "# TODO: Display the shapes of training and testing sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Ô∏è‚É£ Logistic Regression Model Training\n",
        "\n",
        "**Task**: Train a logistic regression model on the training data.\n",
        "\n",
        "**Requirements**:\n",
        "- Initialize LogisticRegression with appropriate parameters\n",
        "- Fit the model on training data\n",
        "- Use cross-validation if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Initialize the Logistic Regression model\n",
        "# Consider parameters like random_state, max_iter\n",
        "\n",
        "# TODO: Train the model on training data\n",
        "\n",
        "# TODO: Display model parameters and coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9Ô∏è‚É£ Model Evaluation and Performance Analysis\n",
        "\n",
        "**Task**: Evaluate the trained model on both training and testing data.\n",
        "\n",
        "**Requirements**:\n",
        "- Make predictions on both training and testing sets\n",
        "- Calculate various classification metrics\n",
        "- Create confusion matrix\n",
        "- Analyze model performance and potential overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Make predictions on training and testing sets\n",
        "\n",
        "# TODO: Calculate accuracy, precision, recall, and F1-score for both sets\n",
        "\n",
        "# TODO: Display classification report\n",
        "\n",
        "# TODO: Create and visualize confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create a comprehensive performance comparison\n",
        "# Compare training vs testing performance to check for overfitting\n",
        "\n",
        "# TODO: Visualize model performance metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîü Feature Importance Analysis\n",
        "\n",
        "**Task**: Analyze which features most strongly influence passenger survival.\n",
        "\n",
        "**Requirements**:\n",
        "- Extract and interpret model coefficients\n",
        "- Rank features by importance\n",
        "- Create visualizations for feature importance\n",
        "- Provide insights about survival factors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Extract model coefficients\n",
        "\n",
        "# TODO: Create feature importance visualization\n",
        "\n",
        "# TODO: Rank features by their influence on survival prediction\n",
        "\n",
        "# TODO: Interpret the results and provide insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Evaluation Criteria\n",
        "\n",
        "Your homework will be evaluated based on:\n",
        "\n",
        "1. **Implementation Correctness (40%)**\n",
        "   - Proper data preprocessing and handling of missing values\n",
        "   - Correct implementation of logistic regression\n",
        "   - Appropriate feature engineering and selection\n",
        "   - Proper train-test split methodology\n",
        "\n",
        "2. **Model Performance (30%)**\n",
        "   - Reasonable classification metrics (accuracy, precision, recall, F1-score)\n",
        "   - Proper evaluation methodology\n",
        "   - Analysis of model performance\n",
        "\n",
        "3. **Code Quality and Analysis (20%)**\n",
        "   - Clean, readable code with appropriate comments\n",
        "   - Comprehensive exploratory data analysis\n",
        "   - Good coding practices and organization\n",
        "\n",
        "4. **Feature Importance Analysis (10%)**\n",
        "   - Identification of most important survival factors\n",
        "   - Clear interpretation of model coefficients\n",
        "   - Meaningful insights and conclusions"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
