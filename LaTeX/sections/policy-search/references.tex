\section{References}
\begin{frame}{}
    \LARGE Policy Search: \textbf{References}
\end{frame}

\begin{frame}[allowframebreaks]{References}
\begin{thebibliography}{99}

\bibitem{schulman2015trpo}
Schulman, J., Levine, S., Abbeel, P., Jordan, M., \& Moritz, P. (2015).
\newblock Trust Region Policy Optimization.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine Learning (ICML)}.

\bibitem{schulman2017ppo}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., \& Klimov, O. (2017).
\newblock Proximal Policy Optimization Algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}.

\bibitem{andrychowicz2020onpolicy}
Andrychowicz, M., Baker, B., Chociej, M., et al. (2020).
\newblock What Matters for On-Policy Deep RL?
\newblock \emph{arXiv preprint arXiv:2006.05990}.

\bibitem{haarnoja2018sac}
Haarnoja, T., Zhou, A., Abbeel, P., \& Levine, S. (2018).
\newblock Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.
\newblock In \emph{Proceedings of the 35th International Conference on Machine Learning (ICML)}.

\bibitem{openai_baselines}
OpenAI Baselines.
\newblock \url{https://github.com/openai/baselines}

\bibitem{spinningup}
Spinning Up by OpenAI.
\newblock \url{https://spinningup.openai.com}

\bibitem{berkeley_cs285}
Sergey Levine, Berkeley CS285: Deep Reinforcement Learning.
\newblock \url{https://rail.eecs.berkeley.edu/deeprlcourse-fa21/}

\bibitem{finn_cs224r}
Chelsea Finn \& Karol Hausman, Stanford CS224R: Deep Reinforcement Learning.
\newblock \url{http://cs224r.stanford.edu/}

\bibitem{brunskill_cs234}
Emma Brunskill, Stanford CS234: Reinforcement Learning.
\newblock \url{https://web.stanford.edu/class/cs234/}

\bibitem{achiam_cs294}
Joshua Achiam, Berkeley CS294: Deep Reinforcement Learning.
\newblock \url{http://rail.eecs.berkeley.edu/deeprlcourse-fa17/}

\end{thebibliography}
\end{frame}