\section{References}
\begin{frame}{}
    \LARGE Advanced Computer Vision: \textbf{References}
\end{frame}

\begin{frame}[allowframebreaks]{References}
    \bibliographystyle{ieeetr}
    \begin{thebibliography}{99}
        \bibitem{vaswani2017attention}
        Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., \& Polosukhin, I. (2017).
        Attention is All You Need.
        \emph{Advances in Neural Information Processing Systems}, 30.
        \url{https://arxiv.org/abs/1706.03762}

        \bibitem{dosovitskiy2020vit}
        Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... \& Houlsby, N. (2020).
        An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.
        \emph{International Conference on Learning Representations}.
        \url{https://arxiv.org/abs/2010.11929}

        \bibitem{touvron2021deit}
        Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., \& Jégou, H. (2021).
        Training data-efficient image transformers & distillation through attention.
        \emph{International Conference on Machine Learning}.
        \url{https://arxiv.org/abs/2012.12877}

        \bibitem{liu2021swin}
        Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., ... \& Guo, B. (2021).
        Swin Transformer: Hierarchical Vision Transformer using Shifted Windows.
        \emph{CVPR 2021}.
        \url{https://arxiv.org/abs/2103.14030}

        \bibitem{chen2021ipt}
        Chen, J., Chen, J., Chao, H., \& Yang, M. (2021).
        Pre-Trained Image Processing Transformer.
        \emph{CVPR 2021}.
        \url{https://arxiv.org/abs/2012.00364}

        \bibitem{lu2021survey}
        Lu, Y., Dosovitskiy, A., Houlsby, N., \& Beyer, L. (2021).
        Vision Transformer: A Survey.
        \emph{arXiv preprint arXiv:2111.06091}.
        \url{https://arxiv.org/abs/2111.06091}

        \bibitem{segformer}
        Xie, E., Wang, W., Yu, Z., Anandkumar, A., Alvarez, J. M., \& Luo, P. (2021).
        SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers.
        \emph{NeurIPS 2021}.
        \url{https://arxiv.org/abs/2105.15203}

        \bibitem{setr}
        Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., ... \& Fu, Y. (2021).
        Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers (SETR).
        \emph{CVPR 2021}.
        \url{https://arxiv.org/abs/2012.15840}

        \bibitem{segmenter}
        Strudel, R., Garcia, R., Laptev, I., \& Schmid, C. (2021).
        Segmenter: Transformer for Semantic Segmentation.
        \emph{ICCV 2021}.
        \url{https://arxiv.org/abs/2105.05633}

        \bibitem{clip}
        Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... \& Sutskever, I. (2021).
        Learning Transferable Visual Models From Natural Language Supervision (CLIP).
        \emph{ICML 2021}.
        \url{https://arxiv.org/abs/2103.00020}

        \bibitem{flamingo}
        Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., ... \& Simonyan, K. (2022).
        Flamingo: a Visual Language Model for Few-Shot Learning.
        \emph{arXiv preprint arXiv:2204.14198}.
        \url{https://arxiv.org/abs/2204.14198}

        \bibitem{dinov2}
        Oquab, M., Darcet, T., Moutakanni, T., Vo, D. H., Szafraniec, M., Khalidov, V., ... \& Jegou, H. (2023).
        DINOv2: Learning Robust Visual Features without Supervision.
        \emph{arXiv preprint arXiv:2304.07193}.
        \url{https://arxiv.org/abs/2304.07193}

        \bibitem{cs231n}
        Fei-Fei Li, Y., Li, Y., \& Gao, R.
        Stanford CS231n: Deep Learning for Computer Vision.
        \url{http://cs231n.stanford.edu/}

        \bibitem{waicdl4cv}
        Shocher, A., Bagon, S., Galun, M., \& Dekel, T.
        WAIC DL4CV: Deep Learning for Computer Vision: Fundamentals and Applications.
        \url{https://www.cs.tau.ac.il/~assafshocher/WAIC-DL4CV/}

        \bibitem{umichdlcv}
        Johnson, J.
        UMich EECS 498.008/598.008: Deep Learning for Computer Vision.
        \url{https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2023/}

        \bibitem{vit-playground}
        Hugging Face.
        Vision Transformer Playground.
        \url{https://huggingface.co/spaces/akhaliq/ViT}

        \bibitem{cs231n-slides}
        Stanford CS231n.
        Lecture Slides: Convolutional Neural Networks for Visual Recognition.
        \url{http://cs231n.stanford.edu/slides/}

        \bibitem{umich-slides}
        Justin Johnson.
        UMich EECS 498.008/598.008: Deep Learning for Computer Vision Slides.
        \url{https://web.eecs.umich.edu/~justincj/teaching/eecs498/slides.html}

        \bibitem{pytorch-tutorial}
        PyTorch.
        PyTorch Tutorials: Vision.
        \url{https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html}
    \end{thebibliography}
\end{frame}